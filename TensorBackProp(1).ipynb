{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "af69107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "90c4cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self,data,_children=(),_op=''):\n",
    "        self.data = data\n",
    "        self.grad = np.zeros_like(self.data,dtype=np.float32)\n",
    "        self._backward = lambda: None\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.shape = data.shape\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.data.__repr__())\n",
    "        \n",
    "    def __add__(self,other):\n",
    "        out = Tensor(self.data + other.data,(self,other),'+')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad = np.add(self.grad,out.grad)\n",
    "            other.grad = np.add(self.grad,out.grad)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __mul__(self,other):\n",
    "        other = other if isinstance(other, Tensor) else Tensor(np.array(other))\n",
    "        out = Tensor(np.multiply(self.data,other.data),(self,other),'*')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += np.multiply(other.data,out.grad)\n",
    "            other.grad += np.multiply(self.data,out.grad)\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def matmul(self,other):\n",
    "        out = Tensor(self.data@other.data,(self,other),'@')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += np.dot(out.grad,other.data.T)\n",
    "            other.grad += np.dot(self.data.T,out.grad)\n",
    "        out._backward = _backward\n",
    "        return out    \n",
    "    \n",
    "    def relu(self):\n",
    "        out = Tensor(np.maximum(self.data,0),(self,),'_/')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += (out.data>0) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    def neg(self):\n",
    "        return self*(-1)\n",
    "    \n",
    "    def __sub__(self,other):\n",
    "        return self + other.neg()\n",
    "    \n",
    "    def pow(self,other):\n",
    "        assert isinstance(other,int)\n",
    "        out = Tensor((self.data)**other,(self,),'**')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += other*(self.data**(other-1))*out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def sum(self,axis=None,keepdims=True):\n",
    "        out = Tensor(np.sum(self.data,axis=axis,keepdims=keepdims),(self,),'++')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += np.ones_like(self.data)*out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        out = Tensor(np.tanh(self.data),(self,),'S')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += (1-(out.data**2))*out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "        \n",
    "    def backward(self):\n",
    "        \n",
    "        topo = []\n",
    "        visited = set()\n",
    "        \n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "        self.grad = np.ones_like(self.data,dtype=np.float32)\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "29f13e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "f292ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "aa88b570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.rand(2,4)\n",
    "w1 = np.random.rand(4,2)\n",
    "\n",
    "x1p = torch.tensor(x1,requires_grad=True,dtype=torch.float32)\n",
    "w1p = torch.tensor(w1,requires_grad=True,dtype=torch.float32)\n",
    "\n",
    "x1T = Tensor(x1)\n",
    "w1T = Tensor(w1)\n",
    "\n",
    "hp = x1p.matmul(w1p)\n",
    "hT = x1T.matmul(w1T)\n",
    "\n",
    "hp = hp.tanh()\n",
    "hT = hT.tanh()\n",
    "#print(hp)\n",
    "lossp = (hp).mean()\n",
    "#print(lossp)\n",
    "LossT = hT.sum(axis=1,keepdims=False)\n",
    "LossT = LossT.sum(axis=0,keepdims=False)*(1/4)\n",
    "#print(LossT)\n",
    "\n",
    "\n",
    "\n",
    "lossp.backward()\n",
    "LossT.backward()\n",
    "\n",
    "print(np.allclose(w1p.grad,w1T.grad))\n",
    "print(np.allclose(x1p.grad,x1T.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "a253e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "########OUR ENGINE AGREES WITH PYTORCH ,AND IT IS MORE PRECISE BUT ALSO CONSUMES MORE MEMORY ~~ HOW MUCH NUMPY CONSUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c8a20693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,in_features,out_features,bias=False):\n",
    "        self.w = Tensor(np.random.rand(in_features,out_features)*0.1)\n",
    "        self.b = Tensor(np.random.rand(out_features)) if bias ==True else None\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        out = x.matmul(self.w)\n",
    "        if self.b is not None:\n",
    "            out += self.b\n",
    "        return out\n",
    "    def parameters(self):\n",
    "        if self.b is not None:\n",
    "            return [self.w.data, self.b.data]\n",
    "        else:\n",
    "            return self.w.data\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4eb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b3bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b4261213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0328, 0.0997, 0.0982, 0.1161, 0.0788, 0.0543],\n",
      "        [0.0226, 0.0680, 0.0700, 0.0782, 0.0490, 0.0382]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "array([[0.03279331, 0.09966842, 0.09820385, 0.11610424, 0.07881016,\n",
      "        0.05433672],\n",
      "       [0.02260609, 0.06803438, 0.06997732, 0.07823497, 0.04895923,\n",
      "        0.03820842]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define PyTorch layer\n",
    "lp = torch.nn.Linear(2, 6,bias=False)\n",
    "\n",
    "# Define custom import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define PyTorch layer\n",
    "lp = torch.nn.Linear(2, 6, bias=False)\n",
    "\n",
    "# Define custom layer\n",
    "lT = Layer(2, 6, bias=False)\n",
    "\n",
    "# Generate same weights for both layers\n",
    "lp.weight.data = torch.tensor(lT.w.data.T, dtype=torch.float32)\n",
    "# lp.bias.data = torch.tensor(lT.b.data)\n",
    "\n",
    "# Input tensor\n",
    "x = np.random.rand(2, 2)\n",
    "xp = torch.tensor(x, requires_grad=True, dtype=torch.float32)\n",
    "lt = Tensor(x)\n",
    "\n",
    "# Compute outputs\n",
    "p = lp(xp)\n",
    "t = lT(lt)\n",
    "\n",
    "# Compare outputs\n",
    "print(p)\n",
    "print(t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "80e9b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "##also same LAYER WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "9d3bf384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.05030832, 0.00137684, 0.07728266, 0.08826412],\n",
       "        [0.0364886 , 0.06153962, 0.00753812, 0.0368824 ],\n",
       "        [0.09331401, 0.06513781, 0.03972026, 0.07887301]]),\n",
       " array([[0.03168361, 0.05680987, 0.08691274, 0.04361734],\n",
       "        [0.08021476, 0.01437668, 0.0704261 , 0.07045813],\n",
       "        [0.02187921, 0.09248676, 0.04421408, 0.0909316 ],\n",
       "        [0.00598092, 0.01842871, 0.00473553, 0.06748809]]),\n",
       " array([[0.05946248],\n",
       "        [0.05333102],\n",
       "        [0.00433241],\n",
       "        [0.05614331]])]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP = [Layer(3,4),Layer(4,4),Layer(4,1)]\n",
    "MLPparams = [l.parameters() for l in MLP ]\n",
    "MLPparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9bfcb223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(4, 4)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in MLP:\n",
    "    print(layer.w.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "967f2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor(np.random.rand(4,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b958ba1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (4, 3))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP[0].w.shape,x.shape#,MLP[0](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "9c41e5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00475852])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Tensor(np.array([2.0, 3.0, -1.0]))\n",
    "\n",
    "for l in MLP:\n",
    "    x = l(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "e0f4eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = Tensor(np.array([\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]))\n",
    "ys = Tensor(np.array([1.0, -1.0, -1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "816d6291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390de17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f0aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966ed94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c94e34a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2,2))\n",
    "b = np.ones((2,2))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3be8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0e34ec14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Tensor(a)\n",
    "b = Tensor(b)\n",
    "\n",
    "c = b.neg()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f14009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ce558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601cbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950826d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b7e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3deb1716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fd958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7858191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995fa7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdefe06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e0379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18aad5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb5bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
